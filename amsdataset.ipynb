{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1lOMG4LoXT6w3pvpcqI-blEoN6WEfGBnp","authorship_tag":"ABX9TyP8EjD+pOdgQ/Iv1waNdIDy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","vehicles = pd.read_csv(\"logistics_dataset_with_maintenance_required.csv\")\n","usage = pd.read_csv(\"synthetic_telemetry_data.csv\")\n","maintenance = pd.read_csv(\"vehicle_maintenance_data.csv\")\n","\n","vehicles.head(), usage.head(), maintenance.head()\n"],"metadata":{"id":"jVXJRbv0BZyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vehicles.info())\n","print(usage.info())\n","print(maintenance.info())\n"],"metadata":{"id":"Gsre_K3YBxhy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","def find_file(keyword):\n","    for f in os.listdir():\n","        if keyword.lower() in f.lower():\n","            return f\n","    return None\n","\n","file_logistics = find_file(\"logistics\")\n","file_vehicle = find_file(\"vehicle\")\n","file_telemetry = find_file(\"telemetry\")\n","\n","print(\"File ditemukan:\")\n","print(\"â€¢ Logistics:\", file_logistics)\n","print(\"â€¢ Vehicle:\", file_vehicle)\n","print(\"â€¢ Telemetry:\", file_telemetry)\n","\n","df_logistics = pd.read_csv(file_logistics)\n","df_vehicle = pd.read_csv(file_vehicle)\n","df_telemetry = pd.read_csv(file_telemetry)\n","\n","print(\"=== df_logistics ===\")\n","display(df_logistics.head())\n"],"metadata":{"id":"-PrNaDMvB1tX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== LOGISTICS COLUMNS ===\")\n","print(df_logistics.columns)\n","\n","print(\"\\n=== VEHICLE COLUMNS ===\")\n","print(df_vehicle.columns)\n","\n","print(\"\\n=== TELEMETRY COLUMNS ===\")\n","print(df_telemetry.columns)\n"],"metadata":{"id":"3d-wGfHZFAy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalisasi semua kolom jadi lowercase dan hapus spasi\n","df_logistics.columns = df_logistics.columns.str.lower().str.strip()\n","df_vehicle.columns = df_vehicle.columns.str.lower().str.strip()\n","df_telemetry.columns = df_telemetry.columns.str.lower().str.strip()\n","\n","print(\"=== LOGISTICS COLUMNS ===\")\n","print(df_logistics.columns)\n","\n","print(\"\\n=== VEHICLE COLUMNS ===\")\n","print(df_vehicle.columns)\n","\n","print(\"\\n=== TELEMETRY COLUMNS ===\")\n","print(df_telemetry.columns)\n"],"metadata":{"id":"p_95LBiYCyvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df_logistics.columns)\n"],"metadata":{"id":"tt3T6e6CDr5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Samakan tipe ID dulu\n","# Samakan tipe ID dulu\n","df_logistics[\"vehicle_id\"] = df_logistics[\"vehicle_id\"].astype(str).str.strip()\n","df_telemetry[\"vehicle_id\"] = df_telemetry[\"vehicle_id\"].astype(str).str.strip()\n","\n","# Merge Logistics Ã— Telemetry\n","df_merge1 = df_logistics.merge(df_telemetry, on=\"vehicle_id\", how=\"left\")\n","\n","\n","# Merge 1 â€” Logistics Ã— Telemetry\n","df_L_T = df_logistics.merge(df_telemetry, on=\"vehicle_id\", how=\"left\")\n","\n","# Merge 2 â€” Logistics+Telemetry Ã— VehicleModel\n","df_final = df_L_T.merge(\n","    df_vehicle,\n","    left_on=\"make_and_model\",\n","    right_on=\"vehicle_model\",\n","    how=\"left\"\n",")\n","\n","display(df_final.head())\n","print(\"Total kolom:\", len(df_final.columns))\n"],"metadata":{"id":"Rs27FdRXFT6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Samakan tipe ID\n","df_logistics[\"vehicle_id\"] = df_logistics[\"vehicle_id\"].astype(str).str.strip()\n","df_telemetry[\"vehicle_id\"] = df_telemetry[\"vehicle_id\"].astype(str).str.strip()\n","\n","# 2. MERGE 1 â€” Logistics Ã— Telemetry\n","df_L_T = df_logistics.merge(df_telemetry, on=\"vehicle_id\", how=\"left\")\n","\n","# 3. MERGE 2 â€” merge df_vehicle via model name\n","df_final = df_L_T.merge(\n","    df_vehicle,\n","    left_on=\"make_and_model\",\n","    right_on=\"vehicle_model\",\n","    how=\"left\"\n",")\n","\n","display(df_final.head())\n","print(\"Total kolom:\", len(df_final.columns))\n","\n","df_final.to_csv(\"AMS_SUPER_DATASET.csv\", index=False)\n"],"metadata":{"id":"CDrmfRwKEmuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get install graphviz\n","!pip install graphviz\n"],"metadata":{"id":"nQUBkfDvGlEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from graphviz import Digraph\n","\n","dfd0 = Digraph(\"DFD0\", format=\"png\")\n","dfd0.attr(rankdir='LR', size=\"8,5\")\n","\n","# External entities\n","dfd0.node(\"Admin\", \"Admin / Fleet Manager\", shape=\"rectangle\")\n","dfd0.node(\"Sensors\", \"Vehicle Sensors / Telemetry System\", shape=\"rectangle\")\n","dfd0.node(\"Maint\", \"Maintenance Team / Workshop\", shape=\"rectangle\")\n","\n","# Process\n","dfd0.node(\"AMS\", \"Automobile Management System\", shape=\"circle\")\n","\n","# Flows\n","dfd0.edge(\"Admin\", \"AMS\", label=\"Input Vehicle Data\")\n","dfd0.edge(\"Sensors\", \"AMS\", label=\"Telemetry Data\")\n","dfd0.edge(\"Maint\", \"AMS\", label=\"Service Reports\")\n","\n","dfd0.edge(\"AMS\", \"Admin\", label=\"Vehicle Health Report\")\n","dfd0.edge(\"AMS\", \"Maint\", label=\"Maintenance Schedule\")\n","dfd0.edge(\"AMS\", \"Admin\", label=\"Alerts\")\n","\n","dfd0.render(\"/content/DFD_Level0\")\n"],"metadata":{"id":"zklvircFGqPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from graphviz import Digraph\n","\n","dfd1 = Digraph(\"DFD1\", format=\"png\")\n","dfd1.attr(rankdir='LR', size=\"12,6\")\n","\n","# External entities\n","dfd1.node(\"Admin\", \"Admin / Fleet Manager\", shape=\"rectangle\")\n","dfd1.node(\"Sensors\", \"Vehicle Sensors\", shape=\"rectangle\")\n","dfd1.node(\"Maint\", \"Maintenance Team\", shape=\"rectangle\")\n","\n","# Processes\n","dfd1.node(\"P1\", \"1. Vehicle Data\\nManagement\", shape=\"circle\")\n","dfd1.node(\"P2\", \"2. Telemetry\\nProcessing\", shape=\"circle\")\n","dfd1.node(\"P3\", \"3. Maintenance\\nManagement\", shape=\"circle\")\n","dfd1.node(\"P4\", \"4. Analytics &\\nReporting\", shape=\"circle\")\n","\n","# Data Stores\n","dfd1.node(\"D1\", \"Vehicle DB\", shape=\"folder\")\n","dfd1.node(\"D2\", \"Telemetry DB\", shape=\"folder\")\n","dfd1.node(\"D3\", \"Maintenance DB\", shape=\"folder\")\n","dfd1.node(\"D4\", \"Analytics Reports\", shape=\"folder\")\n","\n","# Flows\n","dfd1.edge(\"Admin\", \"P1\", label=\"Vehicle Info\")\n","dfd1.edge(\"P1\", \"D1\")\n","\n","dfd1.edge(\"Sensors\", \"P2\", label=\"Telemetry\")\n","dfd1.edge(\"P2\", \"D2\")\n","\n","dfd1.edge(\"Admin\", \"P3\", label=\"Service Request\")\n","dfd1.edge(\"Maint\", \"P3\", label=\"Service Reports\")\n","dfd1.edge(\"P3\", \"D3\")\n","\n","dfd1.edge(\"P1\", \"P4\")\n","dfd1.edge(\"P2\", \"P4\")\n","dfd1.edge(\"P3\", \"P4\")\n","dfd1.edge(\"P4\", \"D4\")\n","\n","dfd1.edge(\"P4\", \"Admin\", label=\"Health Report\")\n","dfd1.edge(\"P4\", \"Maint\", label=\"Maintenance Alerts\")\n","\n","dfd1.render(\"/content/DFD_Level1\")\n"],"metadata":{"id":"J6El1ko2Gsz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/DFD_Level1.png\")\n"],"metadata":{"id":"Qq5t41rsHPwC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files.download(\"/content/DFD_Level0.png\")\n"],"metadata":{"id":"l7Ztu54rHYdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================\n","# COLAB: GENERATE DIAGRAM AMS\n","# - CFD, DFD Level 0, DFD Level 1, CSPEC\n","# - Render PNG, tampilkan, lalu auto-download\n","# ============================\n","\n","# 1) Install Graphviz (hanya di Colab; abaikan jika sudah terpasang)\n","!apt-get -qq update\n","!apt-get -qq install -y graphviz\n","!pip -q install graphviz\n","\n","# 2) Import libs\n","from graphviz import Digraph\n","from IPython.display import Image, display\n","from google.colab import files\n","import os, sys, time\n","\n","# helper: render, show, download\n","def render_and_save(dot_obj, out_path):\n","    # render creates out_path + format; graphviz will create out_path+'.png'\n","    base, ext = os.path.splitext(out_path)\n","    # dot.render expects filename without extension typically; use base\n","    dot_obj.render(base, format='png', cleanup=True)\n","    png_path = base + \".png\"\n","    # Small wait to ensure file is written\n","    for _ in range(5):\n","        if os.path.exists(png_path):\n","            break\n","        time.sleep(0.2)\n","    if not os.path.exists(png_path):\n","        raise RuntimeError(\"Rendering failed, file not found: \" + png_path)\n","    display(Image(png_path))\n","    files.download(png_path)\n","    return png_path\n","\n","# ============================\n","# 3) CFD (Component / Context Flow Diagram)\n","# ============================\n","cfd = Digraph(\"CFD_AMS\", format=\"png\")\n","cfd.attr(rankdir='LR', size=\"12,6\")\n","\n","# Components / nodes\n","cfd.node(\"Admin\", \"Admin / Fleet Manager\", shape=\"rectangle\")\n","cfd.node(\"Sensor\", \"Telemetry Sensor Unit\", shape=\"rectangle\")\n","cfd.node(\"DB1\", \"Vehicle Database\", shape=\"folder\")\n","cfd.node(\"DB2\", \"Telemetry Database\", shape=\"folder\")\n","cfd.node(\"DB3\", \"Maintenance Database\", shape=\"folder\")\n","\n","cfd.node(\"Proc1\", \"Data Collector\", shape=\"component\")\n","cfd.node(\"Proc2\", \"Preprocessing Engine\", shape=\"component\")\n","cfd.node(\"Proc3\", \"Maintenance Analyzer\", shape=\"component\")\n","cfd.node(\"Proc4\", \"Health Scoring Engine\", shape=\"component\")\n","cfd.node(\"Proc5\", \"Reporting Module\", shape=\"component\")\n","\n","# Flows\n","cfd.edge(\"Admin\", \"Proc1\", label=\"Vehicle Info Input\")\n","cfd.edge(\"Sensor\", \"Proc1\", label=\"Raw Telemetry Stream\")\n","cfd.edge(\"Proc1\", \"DB1\", label=\"Store Vehicle Data\")\n","cfd.edge(\"Proc1\", \"DB2\", label=\"Store Telemetry Data\")\n","\n","cfd.edge(\"DB1\", \"Proc2\", label=\"Fetch Vehicle Data\")\n","cfd.edge(\"DB2\", \"Proc2\", label=\"Fetch Telemetry Data\")\n","cfd.edge(\"Proc2\", \"Proc3\", label=\"Processed Signals\")\n","\n","cfd.edge(\"Proc3\", \"DB3\", label=\"Update Maintenance History\")\n","cfd.edge(\"DB3\", \"Proc4\", label=\"Maintenance Logs\")\n","\n","cfd.edge(\"Proc2\", \"Proc4\", label=\"Cleaned Metrics\")\n","cfd.edge(\"Proc4\", \"Proc5\", label=\"Health Score, Alert Flags\")\n","\n","cfd.edge(\"Proc5\", \"Admin\", label=\"Reports & Alerts\")\n","\n","# Render CFD\n","print(\"Rendering CFD...\")\n","render_and_save(cfd, \"/content/CFD_AMS.png\")\n","\n","# ============================\n","# 4) DFD Level 0 (Context Diagram)\n","# ============================\n","dfd0 = Digraph(\"DFD0_AMS\", format=\"png\")\n","dfd0.attr(rankdir='LR', size=\"8,5\")\n","\n","# External entities\n","dfd0.node(\"AdminE\", \"Admin / Fleet Manager\", shape=\"rectangle\")\n","dfd0.node(\"SensorsE\", \"Vehicle Sensors / Telemetry\", shape=\"rectangle\")\n","dfd0.node(\"MaintenanceE\", \"Maintenance Team / Workshop\", shape=\"rectangle\")\n","\n","# Process (single bubble)\n","dfd0.node(\"AMS\", \"Automobile Management System\", shape=\"circle\")\n","\n","# Flows\n","dfd0.edge(\"AdminE\", \"AMS\", label=\"Input Vehicle Data\")\n","dfd0.edge(\"SensorsE\", \"AMS\", label=\"Telemetry Data\")\n","dfd0.edge(\"MaintenanceE\", \"AMS\", label=\"Service Reports\")\n","\n","dfd0.edge(\"AMS\", \"AdminE\", label=\"Vehicle Health Report\")\n","dfd0.edge(\"AMS\", \"MaintenanceE\", label=\"Maintenance Schedule\")\n","dfd0.edge(\"AMS\", \"AdminE\", label=\"Alerts & Anomaly Flags\")\n","\n","# Render DFD Level 0\n","print(\"Rendering DFD Level 0...\")\n","render_and_save(dfd0, \"/content/DFD_Level0.png\")\n","\n","# ============================\n","# 5) DFD Level 1 (Decomposition)\n","# ============================\n","dfd1 = Digraph(\"DFD1_AMS\", format=\"png\")\n","dfd1.attr(rankdir='LR', size=\"12,6\")\n","\n","# Entities\n","dfd1.node(\"AdminE\", \"Admin / Fleet Manager\", shape=\"rectangle\")\n","dfd1.node(\"SensorsE\", \"Vehicle Sensors\", shape=\"rectangle\")\n","dfd1.node(\"MaintenanceE\", \"Maintenance Team\", shape=\"rectangle\")\n","\n","# Processes\n","dfd1.node(\"P1\", \"1. Vehicle Data\\nManagement\", shape=\"circle\")\n","dfd1.node(\"P2\", \"2. Telemetry\\nProcessing\", shape=\"circle\")\n","dfd1.node(\"P3\", \"3. Maintenance\\nManagement\", shape=\"circle\")\n","dfd1.node(\"P4\", \"4. Analytics &\\nReporting\", shape=\"circle\")\n","\n","# Data Stores\n","dfd1.node(\"D1\", \"Vehicle Database\", shape=\"folder\")\n","dfd1.node(\"D2\", \"Telemetry Database\", shape=\"folder\")\n","dfd1.node(\"D3\", \"Maintenance Database\", shape=\"folder\")\n","dfd1.node(\"D4\", \"Analytics Reports\", shape=\"folder\")\n","\n","# Flows\n","dfd1.edge(\"AdminE\", \"P1\", label=\"Vehicle Info\")\n","dfd1.edge(\"P1\", \"D1\", label=\"Save Vehicle Record\")\n","\n","dfd1.edge(\"SensorsE\", \"P2\", label=\"Telemetry Stream\")\n","dfd1.edge(\"P2\", \"D2\", label=\"Store Telemetry\")\n","\n","dfd1.edge(\"AdminE\", \"P3\", label=\"Maintenance Request\")\n","dfd1.edge(\"MaintenanceE\", \"P3\", label=\"Service Reports\")\n","dfd1.edge(\"P3\", \"D3\", label=\"Update Maintenance Record\")\n","\n","dfd1.edge(\"P1\", \"P4\", label=\"Vehicle Data for Analytics\")\n","dfd1.edge(\"P2\", \"P4\", label=\"Telemetry Data for Analytics\")\n","dfd1.edge(\"P3\", \"P4\", label=\"Maintenance Data for Analytics\")\n","dfd1.edge(\"P4\", \"D4\", label=\"Save Reports\")\n","\n","dfd1.edge(\"P4\", \"AdminE\", label=\"Health Report\")\n","dfd1.edge(\"P4\", \"MaintenanceE\", label=\"Maintenance Alerts\")\n","\n","# Render DFD Level 1\n","print(\"Rendering DFD Level 1...\")\n","render_and_save(dfd1, \"/content/DFD_Level1.png\")\n","\n","# ============================\n","# 6) CSPEC / STD (State Transition Diagram)\n","#    We'll create a simple state-machine style diagram using graphviz.\n","# ============================\n","cspec = Digraph(\"CSPEC_AMS\", format=\"png\")\n","cspec.attr(rankdir='TB', size=\"8,6\")\n","\n","# States as nodes\n","cspec.node(\"Inaktif\", \"Inaktif\", shape=\"ellipse\", style=\"filled\", fillcolor=\"lightgrey\")\n","cspec.node(\"InputData\", \"Input Data\", shape=\"ellipse\")\n","cspec.node(\"Penggunaan\", \"Penggunaan\", shape=\"ellipse\")\n","cspec.node(\"Maintenance\", \"Maintenance\", shape=\"ellipse\")\n","\n","# Transitions\n","cspec.edge(\"Inaktif\", \"InputData\", label=\"Mulai Input / Admin\")\n","cspec.edge(\"InputData\", \"Inaktif\", label=\"Selesai Input / Simpan\")\n","cspec.edge(\"Inaktif\", \"Penggunaan\", label=\"Mulai Penggunaan / Driver\")\n","cspec.edge(\"Penggunaan\", \"Inaktif\", label=\"Selesai Penggunaan\")\n","cspec.edge(\"Inaktif\", \"Maintenance\", label=\"Aktivasi Servis / Teknisi\")\n","cspec.edge(\"Maintenance\", \"Inaktif\", label=\"Selesai Servis\")\n","cspec.edge(\"InputData\", \"Maintenance\", label=\"Temuan Masalah\")\n","cspec.edge(\"Maintenance\", \"Penggunaan\", label=\"Selesai Perbaikan -> Siap Pakai\")\n","\n","# Render CSPEC\n","print(\"Rendering CSPEC (State Diagram)...\")\n","render_and_save(cspec, \"/content/CSPEC_AMS.png\")\n","\n","print(\"Semua diagram sudah dirender, ditampilkan, dan di-download otomatis.\")\n"],"metadata":{"id":"Pe5f-WCiPOYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================\n","# INSTALL (Colab)\n","# ============================\n","!apt-get -qq install -y graphviz\n","!pip -q install graphviz\n","\n","from graphviz import Digraph\n","from IPython.display import Image, display\n","from google.colab import files\n","import os, time\n","\n","# Helper\n","def render_and_show(dot, filename):\n","    base = filename.replace(\".png\", \"\")\n","    dot.render(base, format=\"png\", cleanup=True)\n","    time.sleep(0.3)\n","    display(Image(base + \".png\"))\n","    files.download(base + \".png\")\n","\n","# ============================\n","# CSPEC / State Transition Diagram\n","# ============================\n","cspec = Digraph(\"CSPEC_AMS\", format=\"png\")\n","cspec.attr(rankdir='TB', size=\"7,8\")\n","\n","cspec.node(\"Idle\", \"Idle / Inactive\", shape=\"ellipse\", style=\"filled\", fillcolor=\"lightgrey\")\n","cspec.node(\"InputData\", \"Input Data\", shape=\"ellipse\")\n","cspec.node(\"Usage\", \"Vehicle Usage / Operation\", shape=\"ellipse\")\n","cspec.node(\"Maint\", \"Maintenance\", shape=\"ellipse\")\n","\n","# Transitions\n","cspec.edge(\"Idle\", \"InputData\", label=\"Admin Input\")\n","cspec.edge(\"InputData\", \"Idle\", label=\"Save / Done\")\n","\n","cspec.edge(\"Idle\", \"Usage\", label=\"Vehicle Operated\")\n","cspec.edge(\"Usage\", \"Idle\", label=\"Operation Ended\")\n","\n","cspec.edge(\"Idle\", \"Maint\", label=\"Alert / Scheduled\")\n","cspec.edge(\"InputData\", \"Maint\", label=\"Issue Found\")\n","cspec.edge(\"Maint\", \"Idle\", label=\"Service Completed\")\n","cspec.edge(\"Maint\", \"Usage\", label=\"Ready to Operate\")\n","\n","# Render\n","render_and_show(cspec, \"/content/CSPEC_AMS.png\")\n"],"metadata":{"id":"Ahbm8VnfP6m_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sklearn\n","import importlib\n","importlib.reload(sklearn)\n"],"metadata":{"id":"qq3-Q33RQrpl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import sklearn\n","import scipy\n","\n","print(\"NumPy :\", np.__version__)\n","print(\"SciPy :\", scipy.__version__)\n","print(\"Sklearn :\", sklearn.__version__)\n"],"metadata":{"id":"9BQl21GYUXKH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== LOGISTICS COLUMNS ===\")\n","print(df_logistics.columns.tolist(), \"\\n\")\n","\n","print(\"=== VEHICLE COLUMNS ===\")\n","print(df_vehicle.columns.tolist(), \"\\n\")\n","\n","print(\"=== TELEMETRY COLUMNS ===\")\n","print(df_telemetry.columns.tolist(), \"\\n\")\n"],"metadata":{"id":"PIR-t_dMUku3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== LOGISTICS COLUMNS ===\")\n","for c in df_logistics.columns:\n","    print(c)\n","\n","print(\"\\n=== VEHICLE COLUMNS ===\")\n","for c in df_vehicle.columns:\n","    print(c)\n","\n","print(\"\\n=== TELEMETRY COLUMNS ===\")\n","for c in df_telemetry.columns:\n","    print(c)\n"],"metadata":{"id":"_uGL4WxFVEOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# ============================================================\n","# 1) LOAD DATA\n","# ============================================================\n","df_logistics = pd.read_csv(\"/content/logistics_dataset_with_maintenance_required.csv\")\n","df_vehicle   = pd.read_csv(\"/content/vehicle_maintenance_data.csv\")\n","df_telemetry = pd.read_csv(\"/content/synthetic_telemetry_data.csv\")\n","\n","# ============================================================\n","# 2) NORMALISASI KOLOM\n","# ============================================================\n","def normalize(df):\n","    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n","    return df\n","\n","df_logistics = normalize(df_logistics)\n","df_vehicle   = normalize(df_vehicle)\n","df_telemetry = normalize(df_telemetry)\n","\n","# ============================================================\n","# 3) PASTIKAN LOGISTICS & TELEMETRY PUNYA \"vehicle_id\"\n","# ============================================================\n","# Rename jika ada variasi nama\n","rename_map = {\n","    \"vehicle_id\": \"vehicle_id\",\n","    \"vehicleid\": \"vehicle_id\",\n","    \"vehicle-id\": \"vehicle_id\",\n","}\n","\n","for df in [df_logistics, df_telemetry]:\n","    for col in df.columns:\n","        if col.replace(\"_\",\"\") in [\"vehicleid\", \"vehicle_id\", \"vehicle-id\"]:\n","            df.rename(columns={col: \"vehicle_id\"}, inplace=True)\n","\n","# ============================================================\n","# 4) DATA VEHICLE TIDAK PUNYA ID â€” BUAT SENDIRI\n","# ============================================================\n","df_vehicle[\"vehicle_id\"] = df_vehicle.index.astype(str)\n","\n","# ============================================================\n","# 5) UBAH SEMUA VEHICLE_ID JADI STRING\n","# ============================================================\n","df_logistics[\"vehicle_id\"] = df_logistics[\"vehicle_id\"].astype(str)\n","df_telemetry[\"vehicle_id\"] = df_telemetry[\"vehicle_id\"].astype(str)\n","\n","# ============================================================\n","# 6) MERGE FINAL â€” DIJAMIN TANPA ERROR\n","# ============================================================\n","df_final = (\n","    df_logistics\n","    .merge(df_telemetry, on=\"vehicle_id\", how=\"left\")\n","    .merge(df_vehicle,   on=\"vehicle_id\", how=\"left\")\n",")\n","\n","print(\"MERGE SUKSES! Bentuk df_final =\", df_final.shape)\n","df_final.head()\n"],"metadata":{"id":"DFb7w_ToVYnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== RANDOM FOREST PREDICTIVE MAINTENANCE ===\")\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import (\n","    classification_report,\n","    confusion_matrix,\n","    roc_auc_score\n",")\n","from sklearn.preprocessing import LabelEncoder\n","\n","# ============================================================\n","# 1) PAKAI DATASET FINAL HASIL MERGE\n","# ============================================================\n","df = df_final.copy()\n","\n","print(\"Dataset shape:\", df.shape)\n","\n","# ============================================================\n","# 2) CARI TARGET OTOMATIS\n","# ============================================================\n","possible_targets = [\n","    \"Maintenance_Required\",\n","    \"Need_Maintenance\",\n","    \"maintenance_required\",\n","    \"maintenance_flag\"\n","]\n","\n","target = None\n","for t in possible_targets:\n","    if t in df.columns:\n","        target = t\n","        break\n","\n","if target is None:\n","    raise ValueError(\"âš ï¸ Tidak ditemukan kolom target Maintenance!\")\n","\n","print(\"Target ditemukan:\", target)\n","\n","# ============================================================\n","# 3) DROP kolom yang tidak berguna\n","# ============================================================\n","drop_cols = [\n","    \"timestamp\",\n","    \"failure_date\",\n","    \"failure_type\",\n","    \"brand\",\n","    \"Route_Info\"\n","]\n","\n","df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n","\n","# ============================================================\n","# 4) HANDLE MISSING VALUE\n","# ============================================================\n","df = df.fillna(df.median(numeric_only=True))  # numeric\n","df = df.fillna(\"Unknown\")                    # categorical\n","\n","# ============================================================\n","# 5) ENCODING OTOMATIS UNTUK DATA KATEGORI\n","# ============================================================\n","label_cols = df.select_dtypes(include=[\"object\"]).columns\n","le = LabelEncoder()\n","\n","for col in label_cols:\n","    df[col] = le.fit_transform(df[col].astype(str))\n","\n","# ============================================================\n","# 6) PISAHKAN FITUR & TARGET\n","# ============================================================\n","X = df.drop(columns=[target])\n","y = df[target].astype(int)\n","\n","# ============================================================\n","# 7) TRAIN TEST SPLIT\n","# ============================================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.25, random_state=42, stratify=y\n",")\n","\n","# ============================================================\n","# 8) TRAIN RANDOM FOREST\n","# ============================================================\n","rf = RandomForestClassifier(\n","    n_estimators=300,\n","    max_depth=15,\n","    class_weight=\"balanced\",\n","    random_state=42\n",")\n","\n","rf.fit(X_train, y_train)\n","\n","# ============================================================\n","# 9) PREDIKSI & EVALUASI\n","# ============================================================\n","y_pred = rf.predict(X_test)\n","y_prob = rf.predict_proba(X_test)[:, 1]\n","\n","print(\"\\n=== Classification Report ===\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\n=== Confusion Matrix ===\")\n","print(confusion_matrix(y_test, y_pred))\n","\n","print(\"\\nROC-AUC:\", roc_auc_score(y_test, y_prob))\n","\n","# ============================================================\n","# 10) FEATURE IMPORTANCE\n","# ============================================================\n","importances = pd.DataFrame({\n","    \"Feature\": X.columns,\n","    \"Importance\": rf.feature_importances_\n","}).sort_values(by=\"Importance\", ascending=False)\n","\n","print(\"\\n=== Top 20 Most Influential Features ===\")\n","print(importances.head(20))\n"],"metadata":{"id":"Hmr7VvtwWQcD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=== LSTM PREDICTIVE MAINTENANCE ===\")\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n","\n","# ======================================================\n","# 1) PAKAI DATA MERGE\n","# ======================================================\n","df = df_final.copy()\n","\n","# ======================================================\n","# 2) CARI TARGET OTOMATIS\n","# ======================================================\n","possible_targets = [\n","    \"Maintenance_Required\",\n","    \"Need_Maintenance\",\n","    \"maintenance_required\"\n","]\n","\n","target = None\n","for t in possible_targets:\n","    if t in df.columns:\n","        target = t\n","        break\n","\n","if target is None:\n","    raise ValueError(\"âš ï¸ Target Maintenance tidak ditemukan!\")\n","\n","print(\"Target:\", target)\n","\n","# ======================================================\n","# 3) BERSIHKAN DATA (drop tidak relevan)\n","# ======================================================\n","drop_cols = [\n","    \"timestamp\",\n","    \"failure_date\",\n","    \"failure_type\",\n","    \"brand\",\n","    \"Route_Info\",\n","    \"Vehicle_Model\"\n","]\n","\n","df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n","\n","# ======================================================\n","# 4) ISI MISSING VALUES\n","# ======================================================\n","df = df.fillna(df.median(numeric_only=True))\n","df = df.fillna(\"Unknown\")\n","\n","# ======================================================\n","# 5) ENCODE kolom object\n","# ======================================================\n","obj_cols = df.select_dtypes(include=\"object\").columns\n","le = LabelEncoder()\n","\n","for col in obj_cols:\n","    df[col] = le.fit_transform(df[col].astype(str))\n","\n","# ======================================================\n","# 6) PISAHKAN FITUR & TARGET\n","# ======================================================\n","y = df[target].astype(int)\n","X = df.drop(columns=[target])\n","\n","# ======================================================\n","# 7) SCALER\n","# ======================================================\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# ======================================================\n","# 8) BENTUK SEQUENCE untuk LSTM\n","# ======================================================\n","# LSTM butuh bentuk: (batch, timesteps, features)\n","\n","TIMESTEPS = 10  # makin besar makin bagus (kalau data banyak)\n","\n","def create_sequences(data, labels, timesteps=10):\n","    Xs, ys = [], []\n","    for i in range(len(data) - timesteps):\n","        Xs.append(data[i:i+timesteps])\n","        ys.append(labels[i+timesteps])\n","    return np.array(Xs), np.array(ys)\n","\n","X_seq, y_seq = create_sequences(X_scaled, y, TIMESTEPS)\n","\n","print(\"Sequence shape:\", X_seq.shape)\n","\n","# ======================================================\n","# 9) TRAIN TEST SPLIT\n","# ======================================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n",")\n","\n","# ======================================================\n","# 10) BANGUN MODEL LSTM\n","# ======================================================\n","model = tf.keras.Sequential([\n","    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(TIMESTEPS, X_seq.shape[2])),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.LSTM(32),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(32, activation=\"relu\"),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","\n","model.compile(\n","    optimizer=\"adam\",\n","    loss=\"binary_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","model.summary()\n","\n","# ======================================================\n","# 11) TRAINING MODEL\n","# ======================================================\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=15,\n","    batch_size=64,\n","    validation_split=0.2,\n","    verbose=1\n",")\n","\n","# ======================================================\n","# 12) EVALUASI\n","# ======================================================\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","print(\"\\n=== Classification Report ===\")\n","print(classification_report(y_test, y_pred))\n","\n","print(\"\\n=== Confusion Matrix ===\")\n","print(confusion_matrix(y_test, y_pred))\n","\n","print(\"\\nROC-AUC:\", roc_auc_score(y_test, y_pred_prob))\n"],"metadata":{"id":"RPE5PgCOWjBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# CEK dulu apakah rf_model ada\n","try:\n","    importances = rf_model.feature_importances_\n","    feature_names = X.columns\n","\n","    plt.figure(figsize=(10, 6))\n","\n","    # ambil 15 fitur teratas\n","    idx = np.argsort(importances)[-15:]\n","    plt.barh(range(len(idx)), importances[idx])\n","    plt.yticks(range(len(idx)), [feature_names[i] for i in idx])\n","    plt.title(\"Random Forest â€“ Top 15 Feature Importances\")\n","    plt.xlabel(\"Importance Score\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","except Exception as e:\n","    print(\"âš ï¸ RandomForest model belum ada / variabel rf_model tidak ditemukan:\", e)\n"],"metadata":{"id":"l9BaQkexXaif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n"],"metadata":{"id":"lSBEM2F6G_Z4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df_merge1.copy()\n","\n","target_col = \"maintenance_required\"\n","\n","df = df.dropna(subset=[target_col])\n","\n","df_numeric = df.select_dtypes(include=['float64','int64'])\n","\n","X_2d = df_numeric.drop(target_col, axis=1)\n","y = df_numeric[target_col]\n"],"metadata":{"id":"xycv2B8NHBmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n","    X_2d, y, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"N6Qcz__FHaoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rf_model = RandomForestClassifier(\n","    n_estimators=200,\n","    random_state=42\n",")\n","rf_model.fit(X_train_rf, y_train_rf)\n","rf_pred = rf_model.predict(X_test_rf)\n","\n","print(\"RF OK, shape input:\", X_train_rf.shape)\n"],"metadata":{"id":"XLfuxVv4ICtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X_2d)\n","\n","X_scaled = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n"],"metadata":{"id":"c54N-0HyIMTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_window(data, labels, timesteps=10):\n","    X_out = []\n","    y_out = []\n","\n","    for i in range(len(data) - timesteps):\n","        X_out.append(data[i:i+timesteps])\n","        y_out.append(labels.iloc[i+timesteps])\n","\n","    return np.array(X_out), np.array(y_out)\n","\n","X_lstm, y_lstm = make_window(X_scaled, y, timesteps=10)\n"],"metadata":{"id":"Dr1zld9rINxh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n","    X_lstm, y_lstm, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"at8j13_TIU4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"RF input:\", X_train_rf.shape)\n","print(\"LSTM input:\", X_train_lstm.shape)\n"],"metadata":{"id":"Wp_4zcl5IbJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FIX LSTM SHAPE 4D â†’ 3D\n","X_lstm = np.squeeze(X_lstm, axis=2)\n","\n","print(\"LSTM fixed shape:\", X_lstm.shape)\n","# Harus output: (3083, 10, 53)\n"],"metadata":{"id":"Cce14eFRJGB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n","    X_rf, y, test_size=0.2, random_state=42\n",")\n","\n","X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(\n","    X_lstm_fixed, y, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"tEORETwwJJps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_cols = [\n","    \"engine_failure_imminent\",\n","    \"brake_issue_imminent\",\n","    \"battery_issue_imminent\",\n","    \"maintenance_required\",\n","    \"failure_type\"\n","]\n"],"metadata":{"id":"Er4FZUDY6ugy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = df[target_cols]\n","X = df.drop(columns=target_cols)\n","\n"],"metadata":{"id":"zGusthXe7Q0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"rHRcspMx7Xlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.dropna()\n"],"metadata":{"id":"MEknR_d87awh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"synthetic_telemetry_data.csv\")  # atau data asli lainnya\n"],"metadata":{"id":"7Q4BuSt37tzq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LOSS\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history[\"loss\"])\n","plt.plot(history.history[\"val_loss\"])\n","plt.title(\"LSTM Training Loss Curve\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Train Loss\", \"Validation Loss\"])\n","plt.grid(True)\n","plt.show()\n","\n","# ACCURACY\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history[\"accuracy\"])\n","plt.plot(history.history[\"val_accuracy\"])\n","plt.title(\"LSTM Training Accuracy Curve\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend([\"Train Acc\", \"Val Acc\"])\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"BUDLoz9iXnF_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install streamlit pyngrok plotly\n"],"metadata":{"id":"fAJZsPPOYVnE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile ams_dashboard.py\n","import streamlit as st\n","import pandas as pd\n","import plotly.express as px\n","\n","# ============================\n","# LOAD MERGED DATA\n","# ============================\n","df = pd.read_csv(\"merged_ams_data.csv\")\n","\n","st.title(\"ðŸš— AMS â€“ Automobile Management System Dashboard\")\n","st.subheader(\"Visual Analytics â€“ Predictive Maintenance & Telemetry Monitoring\")\n","\n","st.markdown(\"---\")\n","\n","# ============================\n","# 1) VEHICLE OVERVIEW\n","# ============================\n","st.header(\"1ï¸âƒ£ Vehicle Summary\")\n","\n","vehicle_list = df[\"Vehicle_ID\"].unique()\n","selected_vehicle = st.selectbox(\"Pilih Vehicle ID:\", vehicle_list)\n","\n","df_vehicle = df[df[\"Vehicle_ID\"] == selected_vehicle]\n","\n","st.write(df_vehicle.head(3))\n","\n","# ============================\n","# 2) TELEMETRY VISUALIZATION\n","# ============================\n","st.header(\"2ï¸âƒ£ Telemetry Graph\")\n","\n","numeric_cols = [\n","    \"engine_temp_c\", \"engine_rpm\", \"vibration_level\", \"battery_voltage_v\",\n","    \"brake_temp_c\", \"vehicle_speed_kph\"\n","]\n","\n","col = st.selectbox(\"Pilih parameter:\", numeric_cols)\n","\n","fig = px.line(df_vehicle, x=\"timestamp\", y=col, title=f\"{col} vs Time\")\n","st.plotly_chart(fig)\n","\n","# ============================\n","# 3) MAINTENANCE PREDICTION (RF & LSTM)\n","# ============================\n","st.header(\"3ï¸âƒ£ Maintenance Prediction\")\n","\n","st.write(\"Random Forest & LSTM Prediction Results\")\n","\n","if \"rf_pred\" in df.columns and \"lstm_pred\" in df.columns:\n","    st.write(df_vehicle[[\"timestamp\", \"rf_pred\", \"lstm_pred\"]])\n","else:\n","    st.warning(\"Prediksi RF/LSTM belum di-merge ke dataset final.\")\n","\n","# ============================\n","# 4) HEATMAP VEHICLE HEALTH STATUS\n","# ============================\n","st.header(\"4ï¸âƒ£ Vehicle Health Heatmap\")\n","\n","health_cols = [\n","    \"engine_temp_c\", \"oil_pressure_psi\", \"vibration_level\",\n","    \"brake_temp_c\", \"battery_voltage_v\", \"engine_load_percent\"\n","]\n","\n","fig2 = px.imshow(\n","    df_vehicle[health_cols].corr(),\n","    text_auto=True,\n","    title=\"Telemetri Correlation Heatmap\"\n",")\n","\n","st.plotly_chart(fig2)\n","\n","st.markdown(\"---\")\n","st.write(\"Dashboard by Lutpay ðŸš€\")\n"],"metadata":{"id":"I_-vn9TBYb94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_final.to_csv(\"merged_ams_data.csv\", index=False)\n"],"metadata":{"id":"eH8liXogYieR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NGROK_TOKEN = \"35eAG1AOukweu3Y8FpS5puYwxkE_5vcrYCDEN3gP2zV8KrhaB\"\n"],"metadata":{"id":"D8WrFa8tYodL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyngrok==7.0.5 streamlit -q\n","\n","from pyngrok import ngrok\n","\n","# Masukkan token kamu di sini\n","NGROK_TOKEN = \"35eAG1AOukweu3Y8FpS5puYwxkE_5vcrYCDEN3gP2zV8KrhaB\"\n","\n","# Set token\n","ngrok.set_auth_token(NGROK_TOKEN)\n","\n","# Buka tunnel untuk port Streamlit (8501)\n","public_url = ngrok.connect(8501)\n","print(\"Public URL:\", public_url)\n"],"metadata":{"id":"JtqjcVw3drjO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","\n","st.title(\"Test Streamlit di Colab + Ngrok\")\n","st.write(\"Server berjalan dengan sukses!\")\n"],"metadata":{"id":"DMoyWdNYd3DL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&\n"],"metadata":{"id":"HNXiQR-Sd8Up"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["public_url\n"],"metadata":{"id":"HPayIET0eAMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n","!chmod +x cloudflared\n"],"metadata":{"id":"mVlCrHCXedgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n","!chmod +x cloudflared\n"],"metadata":{"id":"lpbl6lNzeg3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&\n"],"metadata":{"id":"eT6FQJ4ieksp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess, time, re\n","\n","# Jalankan tunnel\n","process = subprocess.Popen(\n","    \"./cloudflared tunnel --url http://localhost:8501 --logfile cloudflared.log &\",\n","    shell=True\n",")\n","\n","time.sleep(4)  # tunggu cloudflared booting\n","\n","with open(\"cloudflared.log\") as f:\n","    log = f.read()\n","\n","# Ambil URL publik\n","url = re.findall(r\"https://[-0-9a-z]+\\.trycloudflare\\.com\", log)[0]\n","print(\"ðŸ”— LINK PUBLIC:\", url)\n"],"metadata":{"id":"u6IeAV7Sel_y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import altair as alt\n","\n","# ========== CONFIG ==========\n","st.set_page_config(\n","    page_title=\"Dashboard Data Kamu\",\n","    page_icon=\"ðŸ“Š\",\n","    layout=\"wide\"\n",")\n","\n","# ========== SIDEBAR ==========\n","with st.sidebar:\n","    st.title(\"ðŸ“ Muat Data\")\n","    data_source = st.radio(\"Pilih Sumber Data:\", [\"Upload File\", \"Pakai Path Lokal\"])\n","\n","    df = None\n","\n","    if data_source == \"Upload File\":\n","        file = st.file_uploader(\"Upload CSV / Excel\", type=[\"csv\", \"xlsx\"])\n","        if file:\n","            if file.name.endswith(\".csv\"):\n","                df = pd.read_csv(file)\n","            else:\n","                df = pd.read_excel(file)\n","    else:\n","        path = st.text_input(\"Masukkan path file:\", \"data.csv\")\n","        if st.button(\"Load Data\"):\n","            try:\n","                if path.endswith(\".csv\"):\n","                    df = pd.read_csv(path)\n","                else:\n","                    df = pd.read_excel(path)\n","            except:\n","                st.error(\"Gagal memuat data. Pastikan path benar.\")\n","\n","# ========== MAIN PAGE ==========\n","st.title(\"ðŸ“Š Dashboard Data Kamu\")\n","\n","if df is None:\n","    st.info(\"Silakan muat data terlebih dahulu melalui sidebar.\")\n","else:\n","    st.success(\"Data berhasil dimuat!\")\n","\n","    # ====== TAMPILKAN TABEL ======\n","    st.subheader(\"ðŸ“„ Tabel Data\")\n","    st.dataframe(df, use_container_width=True)\n","\n","    # ====== DESKRIPSI ======\n","    st.subheader(\"ðŸ“ˆ Statistik Deskriptif\")\n","    st.write(df.describe())\n","\n","    # ====== PILIH KOLOM UNTUK CHART ======\n","    st.subheader(\"ðŸ“‰ Visualisasi Data\")\n","    num_cols = df.select_dtypes(include=['number']).columns\n","\n","    if len(num_cols) == 0:\n","        st.warning(\"Tidak ada kolom numerik untuk divisualisasikan.\")\n","    else:\n","        selected_col = st.selectbox(\"Pilih kolom numerik:\", num_cols)\n","\n","        chart = alt.Chart(df.reset_index()).mark_line(point=True).encode(\n","            x=\"index\",\n","            y=selected_col\n","        )\n","        st.altair_chart(chart, use_container_width=True)\n"],"metadata":{"id":"L4cl6QcfgKcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&\n"],"metadata":{"id":"Jhgos4EwgXU9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess, time, re\n","\n","process = subprocess.Popen(\n","    \"./cloudflared tunnel --url http://localhost:8501 --logfile cloudflared.log &\",\n","    shell=True\n",")\n","\n","time.sleep(4)\n","\n","with open(\"cloudflared.log\") as f:\n","    log = f.read()\n","\n","url = re.findall(r\"https://[-0-9a-z]+\\.trycloudflare\\.com\", log)[0]\n","print(\"ðŸ”— LINK KAMU:\", url)\n"],"metadata":{"id":"jDZ0huECgbX1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","\n","st.set_page_config(page_title=\"Multi CSV Loader\", page_icon=\"ðŸ“‚\", layout=\"wide\")\n","\n","st.title(\"ðŸ“‚ Load 3 File CSV Sekaligus\")\n","\n","# --- Sidebar ---\n","st.sidebar.title(\"ðŸ“ Upload 3 CSV\")\n","\n","file1 = st.sidebar.file_uploader(\"Upload CSV 1\", type=[\"csv\"])\n","file2 = st.sidebar.file_uploader(\"Upload CSV 2\", type=[\"csv\"])\n","file3 = st.sidebar.file_uploader(\"Upload CSV 3\", type=[\"csv\"])\n","\n","dfs = {}\n","\n","# Load semua file\n","if file1:\n","    dfs[\"CSV 1\"] = pd.read_csv(file1)\n","\n","if file2:\n","    dfs[\"CSV 2\"] = pd.read_csv(file2)\n","\n","if file3:\n","    dfs[\"CSV 3\"] = pd.read_csv(file3)\n","\n","# Jika TIDAK ada file\n","if len(dfs) == 0:\n","    st.info(\"Upload minimal 1 file CSV melalui sidebar.\")\n","else:\n","    st.success(f\"{len(dfs)} file berhasil dimuat.\")\n","\n","    # --- Tampilkan semua file ---\n","    for name, df in dfs.items():\n","        st.subheader(f\"ðŸ“„ {name}\")\n","        st.dataframe(df, use_container_width=True)\n","        st.write(\"Shape:\", df.shape)\n","        st.markdown(\"---\")\n","\n","    # --- Menu gabungan data ---\n","    if len(dfs) == 3:\n","        st.header(\"ðŸŸ¦ Gabungkan Data (Opsional)\")\n","\n","        merge_option = st.selectbox(\n","            \"Pilih cara menggabungkan data:\",\n","            [\"Concat (menyambung ke bawah)\", \"Merge (berdasarkan kolom tertentu)\"]\n","        )\n","\n","        if merge_option == \"Concat (menyambung ke bawah)\":\n","            combined = pd.concat(dfs.values(), ignore_index=True)\n","            st.subheader(\"ðŸ“˜ Hasil Concat\")\n","            st.dataframe(combined, use_container_width=True)\n","            st.write(\"Shape:\", combined.shape)\n","\n","        else:  # merge\n","            st.info(\"Pilih kolom yang sama di 3 file untuk merge.\")\n","\n","            # Ambil kolom yang sama\n","            common_cols = set.intersection(*[set(df.columns) for df in dfs.values()])\n","\n","            if len(common_cols) == 0:\n","                st.error(\"Tidak ada kolom yang sama untuk merge.\")\n","            else:\n","                col = st.selectbox(\"Pilih kolom merge:\", list(common_cols))\n","\n","                merged = dfs[\"CSV 1\"].merge(dfs[\"CSV 2\"], on=col).merge(dfs[\"CSV 3\"], on=col)\n","                st.subheader(\"ðŸ“˜ Hasil Merge Berdasarkan Kolom\")\n","                st.dataframe(merged, use_container_width=True)\n","                st.write(\"Shape:\", merged.shape)\n"],"metadata":{"id":"_Pwgw6QgiNsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&\n"],"metadata":{"id":"ZKb89us_iPpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(url)\n"],"metadata":{"id":"coBEB0OJiUrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import altair as alt\n","from datetime import datetime\n","import io\n","\n","st.set_page_config(page_title=\"AMS - Automobile Management System\", layout=\"wide\", page_icon=\"ðŸš—\")\n","\n","# -------------------------\n","# Helper functions\n","# -------------------------\n","def load_csv(uploaded_file, default_cols=None):\n","    try:\n","        if uploaded_file is None:\n","            return None\n","        return pd.read_csv(uploaded_file)\n","    except Exception as e:\n","        st.error(f\"Gagal membaca file: {e}\")\n","        return None\n","\n","def ensure_idx(df, key):\n","    if key not in df.columns:\n","        df.insert(0, key, range(1, len(df) + 1))\n","    return df\n","\n","def to_csv_download(df):\n","    buffer = io.StringIO()\n","    df.to_csv(buffer, index=False)\n","    return buffer.getvalue()\n","\n","def next_id(df, id_col):\n","    if df is None or df.empty:\n","        return 1\n","    try:\n","        return int(df[id_col].max()) + 1\n","    except Exception:\n","        return len(df) + 1\n","\n","# -------------------------\n","# Session state initial\n","# -------------------------\n","if \"vehicles\" not in st.session_state:\n","    st.session_state.vehicles = pd.DataFrame(columns=[\"vehicle_id\",\"plate\",\"make\",\"model\",\"year\",\"owner\",\"status\",\"notes\"])\n","if \"maintenance\" not in st.session_state:\n","    st.session_state.maintenance = pd.DataFrame(columns=[\"maintenance_id\",\"vehicle_id\",\"date\",\"type\",\"cost\",\"mileage\",\"notes\"])\n","if \"fuel\" not in st.session_state:\n","    st.session_state.fuel = pd.DataFrame(columns=[\"fuel_id\",\"vehicle_id\",\"date\",\"liters\",\"cost\",\"mileage\",\"station\",\"notes\"])\n","if \"trips\" not in st.session_state:\n","    st.session_state.trips = pd.DataFrame(columns=[\"trip_id\",\"vehicle_id\",\"date\",\"start_km\",\"end_km\",\"distance\",\"purpose\",\"driver\"])\n","\n","# -------------------------\n","# Sidebar\n","# -------------------------\n","st.sidebar.title(\"Data Source & Utilities\")\n","data_mode = st.sidebar.radio(\"Mode Data\", [\"Upload CSV\", \"Use Session (in-memory)\"])\n","\n","uploaded_vehicles = st.sidebar.file_uploader(\"Upload vehicles.csv\", type=[\"csv\"])\n","uploaded_maintenance = st.sidebar.file_uploader(\"Upload maintenance.csv\", type=[\"csv\"])\n","uploaded_fuel = st.sidebar.file_uploader(\"Upload fuel.csv\", type=[\"csv\"])\n","uploaded_trips = st.sidebar.file_uploader(\"Upload trips.csv\", type=[\"csv\"])\n","\n","if data_mode == \"Upload CSV\":\n","    if uploaded_vehicles:\n","        st.session_state.vehicles = load_csv(uploaded_vehicles)\n","    if uploaded_maintenance:\n","        st.session_state.maintenance = load_csv(uploaded_maintenance)\n","    if uploaded_fuel:\n","        st.session_state.fuel = load_csv(uploaded_fuel)\n","    if uploaded_trips:\n","        st.session_state.trips = load_csv(uploaded_trips)\n","\n","st.sidebar.markdown(\"---\")\n","st.sidebar.subheader(\"Quick Actions\")\n","if st.sidebar.button(\"Seed Demo Data\"):\n","    st.session_state.vehicles = pd.DataFrame([\n","        {\"vehicle_id\":1,\"plate\":\"B1234XYZ\",\"make\":\"Toyota\",\"model\":\"Avanza\",\"year\":2018,\"owner\":\"Masjid A\",\"status\":\"Active\",\"notes\":\"\"},\n","        {\"vehicle_id\":2,\"plate\":\"B9876ABC\",\"make\":\"Daihatsu\",\"model\":\"Xenia\",\"year\":2016,\"owner\":\"Masjid B\",\"status\":\"Active\",\"notes\":\"\"},\n","    ])\n","    st.session_state.maintenance = pd.DataFrame([\n","        {\"maintenance_id\":1,\"vehicle_id\":1,\"date\":\"2025-01-15\",\"type\":\"Oil Change\",\"cost\":250000,\"mileage\":42000,\"notes\":\"Rutin\"},\n","    ])\n","    st.session_state.fuel = pd.DataFrame([\n","        {\"fuel_id\":1,\"vehicle_id\":1,\"date\":\"2025-04-01\",\"liters\":40,\"cost\":600000,\"mileage\":43000,\"station\":\"Pertamina\",\"notes\":\"\"},\n","    ])\n","    st.session_state.trips = pd.DataFrame([])\n","\n","# -------------------------\n","# Main Navigation\n","# -------------------------\n","st.title(\"ðŸš— AMS â€” Automobile Management System\")\n","menu = st.radio(\"Menu\", [\n","    \"Dashboard\",\n","    \"Vehicles\",\n","    \"Maintenance\",\n","    \"Fuel & Trips\",\n","    \"Reports\",\n","    \"Predictive Maintenance\",  # â† ADDED\n","    \"Settings\"\n","], horizontal=True)\n","\n","# -------------------------\n","# Dashboard\n","# -------------------------\n","if menu == \"Dashboard\":\n","    st.header(\"Dashboard\")\n","\n","    vdf = st.session_state.vehicles\n","    mdf = st.session_state.maintenance\n","    fdf = st.session_state.fuel\n","    tdf = st.session_state.trips\n","\n","    col1, col2, col3, col4 = st.columns(4)\n","    col1.metric(\"Total Vehicles\", vdf.shape[0])\n","    col2.metric(\"Maintenance Records\", mdf.shape[0])\n","    col3.metric(\"Fuel Records\", fdf.shape[0])\n","    col4.metric(\"Total Trips\", tdf.shape[0])\n","\n","# -------------------------\n","# Vehicles CRUD\n","# -------------------------\n","elif menu == \"Vehicles\":\n","    st.header(\"Vehicles â€” Data Kendaraan\")\n","    vdf = st.session_state.vehicles\n","    st.dataframe(vdf, use_container_width=True)\n","\n","# -------------------------\n","# Maintenance\n","# -------------------------\n","elif menu == \"Maintenance\":\n","    st.header(\"Maintenance â€” Catatan Perawatan\")\n","    mdf = st.session_state.maintenance\n","    st.dataframe(mdf, use_container_width=True)\n","\n","# -------------------------\n","# Fuel & Trips\n","# -------------------------\n","elif menu == \"Fuel & Trips\":\n","    st.header(\"Fuel & Trips\")\n","    st.dataframe(st.session_state.fuel)\n","    st.dataframe(st.session_state.trips)\n","\n","# -------------------------\n","# Reports\n","# -------------------------\n","elif menu == \"Reports\":\n","    st.header(\"Reports & Exports\")\n","    st.write(\"Belum ada fitur laporan detail pada versi ini.\")\n"],"metadata":{"id":"7Vaobn4hjO7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------\n","# Predictive Maintenance\n","# -------------------------\n","elif menu == \"Predictive Maintenance\":\n","    st.header(\"ðŸ”® Predictive Maintenance\")\n","\n","    st.write(\"\"\"\n","    Modul ini melakukan prediksi kebutuhan maintenance kendaraan\n","    menggunakan:\n","    â€¢ Random Forest (tabular)\n","    â€¢ LSTM (time-series)\n","    \"\"\")\n","\n","    pred_file = st.file_uploader(\"Upload dataset predictive maintenance (CSV)\", type=[\"csv\"])\n","\n","    if pred_file:\n","        df_pred = pd.read_csv(pred_file)\n","        st.dataframe(df_pred.head())\n","\n","        st.subheader(\"ðŸ”§ Pilih Fitur & Label\")\n","        label_col = st.selectbox(\"Target (label)\", df_pred.columns)\n","        feature_cols = st.multiselect(\"Fitur\", df_pred.columns.drop(label_col))\n","\n","        # ----------------- RANDOM FOREST -----------------\n","        st.markdown(\"---\")\n","        st.subheader(\"ðŸ§  Random Forest\")\n","\n","        if st.button(\"Train Random Forest\"):\n","            from sklearn.model_selection import train_test_split\n","            from sklearn.ensemble import RandomForestClassifier\n","            from sklearn.metrics import classification_report\n","\n","            X = df_pred[feature_cols]\n","            y = df_pred[label_col]\n","\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","            rf = RandomForestClassifier(n_estimators=250)\n","            rf.fit(X_train, y_train)\n","\n","            preds = rf.predict(X_test)\n","            report = classification_report(y_test, preds, output_dict=True)\n","\n","            st.session_state.rf_model = rf\n","            st.success(\"Random Forest trained!\")\n","            st.json(report)\n","\n","        if \"rf_model\" in st.session_state:\n","            st.subheader(\"ðŸ” RF Prediction\")\n","            inputs = {col: st.number_input(col, float(df_pred[col].min()), float(df_pred[col].max()), float(df_pred[col].median())) for col in feature_cols}\n","\n","            if st.button(\"Predict (RF)\"):\n","                pred = st.session_state.rf_model.predict(pd.DataFrame([inputs]))[0]\n","                st.success(f\"Prediction: {pred}\")\n","\n","        # ----------------- LSTM -----------------\n","        st.markdown(\"---\")\n","        st.subheader(\"ðŸ§  LSTM (Time Series)\")\n","\n","        time_col = st.selectbox(\"Kolom waktu\", df_pred.columns)\n","\n","        if st.button(\"Train LSTM\"):\n","            try:\n","                import tensorflow as tf\n","                from tensorflow.keras.models import Sequential\n","                from tensorflow.keras.layers import LSTM, Dense\n","                from sklearn.preprocessing import MinMaxScaler\n","                import numpy as np\n","\n","                ts = df_pred[[time_col, label_col]].copy()\n","                ts[time_col] = pd.to_datetime(ts[time_col])\n","                ts = ts.sort_values(time_col).set_index(time_col)\n","\n","                scaler = MinMaxScaler()\n","                scaled = scaler.fit_transform(ts)\n","\n","                seq_len = 10\n","                X_ts, y_ts = [], []\n","                for i in range(len(scaled)-seq_len):\n","                    X_ts.append(scaled[i:i+seq_len])\n","                    y_ts.append(scaled[i+seq_len])\n","\n","                X_ts, y_ts = np.array(X_ts), np.array(y_ts)\n","\n","                model = Sequential([\n","                    LSTM(64, input_shape=(seq_len, 1)),\n","                    Dense(1)\n","                ])\n","                model.compile(optimizer=\"adam\", loss=\"mse\")\n","                model.fit(X_ts, y_ts, epochs=10, batch_size=16)\n","\n","                st.session_state.lstm_model = model\n","                st.session_state.lstm_scaler = scaler\n","                st.success(\"LSTM trained!\")\n","            except Exception as e:\n","                st.error(f\"Gagal melatih LSTM: {e}\")\n","\n","        if \"lstm_model\" in st.session_state:\n","            steps = st.number_input(\"Prediksi ke depan (n langkah):\", 1, 60, 10)\n","\n","            if st.button(\"Predict (LSTM)\"):\n","                model = st.session_state.lstm_model\n","                scaler = st.session_state.lstm_scaler\n","\n","                last = scaler.transform(df_pred[[label_col]].values)[-10:].reshape(1,10,1)\n","                preds = []\n","\n","                for _ in range(steps):\n","                    p = model.predict(last)[0][0]\n","                    preds.append(p)\n","                    last = np.roll(last, -1)\n","                    last[0,-1,0] = p\n","\n","                preds = scaler.inverse_transform(np.array(preds).reshape(-1,1))\n","                st.line_chart(preds)\n","\n","# -------------------------\n","# Settings\n","# -------------------------\n","elif menu == \"Settings\":\n","    st.header(\"Settings\")\n","    st.write(\"Pengaturan sistem AMS.\")\n"],"metadata":{"id":"DZpKcMbHl4h8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sed -n '350,500p' app.py\n"],"metadata":{"id":"_4LZoY8Kj23R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wc -l app.py\n"],"metadata":{"id":"w-nGwX3HmWXj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat app.py\n"],"metadata":{"id":"K_ccm8NxmgVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import altair as alt\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","\n","st.set_page_config(page_title=\"AMS - Automobile System\", page_icon=\"ðŸš—\", layout=\"wide\")\n","\n","st.title(\"ðŸš— Automobile Management System (AMS)\")\n","\n","# ----------------------\n","# MENU\n","# ----------------------\n","menu = st.sidebar.radio(\"Navigasi\", [\n","    \"Dashboard\",\n","    \"Load 3 CSV\",\n","    \"Predictive Maintenance\"\n","])\n","\n","# ======================\n","# 1. DASHBOARD\n","# ======================\n","if menu == \"Dashboard\":\n","    st.header(\"ðŸ“Š Dashboard\")\n","    st.info(\"Dashboard masih kosong. Tambahkan fitur nanti.\")\n","\n","# ======================\n","# 2. LOAD 3 CSV MENU\n","# ======================\n","elif menu == \"Load 3 CSV\":\n","    st.header(\"ðŸ“‚ Load 3 File CSV Sekaligus\")\n","\n","    file1 = st.sidebar.file_uploader(\"Upload CSV 1\", type=[\"csv\"])\n","    file2 = st.sidebar.file_uploader(\"Upload CSV 2\", type=[\"csv\"])\n","    file3 = st.sidebar.file_uploader(\"Upload CSV 3\", type=[\"csv\"])\n","\n","    dfs = {}\n","\n","    if file1:\n","        dfs[\"CSV 1\"] = pd.read_csv(file1)\n","    if file2:\n","        dfs[\"CSV 2\"] = pd.read_csv(file2)\n","    if file3:\n","        dfs[\"CSV 3\"] = pd.read_csv(file3)\n","\n","    if len(dfs) == 0:\n","        st.info(\"Upload minimal 1 file CSV.\")\n","    else:\n","        st.success(f\"{len(dfs)} file berhasil dimuat.\")\n","\n","        for name, df in dfs.items():\n","            st.subheader(f\"ðŸ“„ {name}\")\n","            st.dataframe(df, use_container_width=True)\n","            st.write(\"Shape:\", df.shape)\n","            st.markdown(\"---\")\n","\n","        if len(dfs) == 3:\n","            st.subheader(\"ðŸŸ¦ Gabungkan Data\")\n","            mode = st.selectbox(\"Mode Gabung\", [\"Concat\", \"Merge\"])\n","\n","            if mode == \"Concat\":\n","                comb = pd.concat(dfs.values(), ignore_index=True)\n","                st.dataframe(comb)\n","                st.write(\"Shape:\", comb.shape)\n","            else:\n","                st.info(\"Pilih kolom yang sama untuk merge.\")\n","                common_cols = set.intersection(*[set(df.columns) for df in dfs.values()])\n","\n","                if len(common_cols) == 0:\n","                    st.error(\"Tidak ada kolom yang sama untuk merge.\")\n","                else:\n","                    col = st.selectbox(\"Kolom Merge\", list(common_cols))\n","                    merged = dfs[\"CSV 1\"].merge(dfs[\"CSV 2\"], on=col).merge(dfs[\"CSV 3\"], on=col)\n","                    st.dataframe(merged)\n","                    st.write(\"Shape:\", merged.shape)\n","\n","# ======================\n","# 3. PREDICTIVE MAINTENANCE\n","# ======================\n","elif menu == \"Predictive Maintenance\":\n","    st.header(\"ðŸ”® Predictive Maintenance\")\n","\n","    pred_file = st.file_uploader(\"Upload Dataset Predictive Maintenance (CSV)\", type=[\"csv\"])\n","\n","    if pred_file:\n","        df = pd.read_csv(pred_file)\n","        st.dataframe(df.head())\n","\n","        label = st.selectbox(\"Kolom Target\", df.columns)\n","        features = st.multiselect(\"Kolom Fitur\", df.columns.drop(label))\n","\n","        # RANDOM FOREST\n","        st.subheader(\"ðŸ§  Random Forest\")\n","\n","        if st.button(\"Train Random Forest\"):\n","            X = df[features]\n","            y = df[label]\n","\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","            model = RandomForestClassifier(n_estimators=200)\n","            model.fit(X_train, y_train)\n","\n","            preds = model.predict(X_test)\n","            report = classification_report(y_test, preds, output_dict=True)\n","\n","            st.session_state.rf = model\n","            st.success(\"Random Forest dilatih!\")\n","            st.json(report)\n","\n","        if \"rf\" in st.session_state:\n","            st.subheader(\"Prediksi Menggunakan RF\")\n","            sample = {col: st.number_input(col, float(df[col].min()), float(df[col].max())) for col in features}\n","            if st.button(\"Predict (RF)\"):\n","                pred = st.session_state.rf.predict(pd.DataFrame([sample]))[0]\n","                st.success(f\"Hasil Prediksi RF: {pred}\")\n","\n","        # LSTM\n","        st.subheader(\"ðŸ§  LSTM (Time Series)\")\n","        time_col = st.selectbox(\"Kolom Waktu\", df.columns)\n","\n","        if st.button(\"Train LSTM\"):\n","            try:\n","                ts = df[[time_col, label]].copy()\n","                ts[time_col] = pd.to_datetime(ts[time_col])\n","                ts = ts.sort_values(time_col).set_index(time_col)\n","\n","                scaler = MinMaxScaler()\n","                scaled = scaler.fit_transform(ts)\n","\n","                seq_len = 10\n","                X_ts, y_ts = [], []\n","\n","                for i in range(len(scaled) - seq_len):\n","                    X_ts.append(scaled[i:i+seq_len])\n","                    y_ts.append(scaled[i+seq_len])\n","\n","                X_ts, y_ts = np.array(X_ts), np.array(y_ts)\n","\n","                model = Sequential([\n","                    LSTM(64, input_shape=(seq_len, 1)),\n","                    Dense(1)\n","                ])\n","                model.compile(optimizer=\"adam\", loss=\"mse\")\n","                model.fit(X_ts, y_ts, epochs=10, batch_size=16)\n","\n","                st.session_state.lstm = model\n","                st.session_state.scaler = scaler\n","                st.success(\"LSTM dilatih!\")\n","\n","            except Exception as e:\n","                st.error(f\"Error LSTM: {e}\")\n","\n","        if \"lstm\" in st.session_state:\n","            step = st.number_input(\"Predict n langkah ke depan\", 1, 60, 10)\n","\n","            if st.button(\"Predict (LSTM)\"):\n","                scaler = st.session_state.scaler\n","                model = st.session_state.lstm\n","\n","                last = scaler.transform(df[[label]].values)[-10:].reshape(1,10,1)\n","                preds = []\n","\n","                for _ in range(step):\n","                    p = model.predict(last)[0][0]\n","                    preds.append(p)\n","                    last = np.roll(last, -1)\n","                    last[0,-1,0] = p\n","\n","                preds = scaler.inverse_transform(np.array(preds).reshape(-1,1))\n","                st.line_chart(preds)\n","                st.success(\"Prediksi selesai!\")\n"],"metadata":{"id":"9LxUZAtEmwLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/content/log.txt &\n"],"metadata":{"id":"sERICTaznC_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -s https://raw.githubusercontent.com/cloudflare/cloudflared/master/scripts/get-cloudflared.sh | bash\n"],"metadata":{"id":"kcIjPfaYnFJT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n","!chmod +x cloudflared\n"],"metadata":{"id":"waCrq6yHnRET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kill -9 $(pidof cloudflared) 2>/dev/null\n","!kill -9 $(pidof streamlit) 2>/dev/null\n"],"metadata":{"id":"mb2g2iMtnaEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -f cloudflared\n"],"metadata":{"id":"9BCc_mpcnbuH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n","!chmod +x cloudflared\n"],"metadata":{"id":"eIFruBNZne4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!streamlit run app.py &>/dev/null&\n"],"metadata":{"id":"-Oqr6LzMniGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"],"metadata":{"id":"4e0Dg8KFnloU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess, time, re\n","\n","# -----------------------------\n","# KILL proses lama (streamlit + cloudflare)\n","# -----------------------------\n","!kill -9 $(pidof streamlit) 2>/dev/null\n","!kill -9 $(pidof cloudflared) 2>/dev/null\n","\n","# -----------------------------\n","# Install streamlit + cloudflared\n","# -----------------------------\n","!pip install -q streamlit\n","!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n","!chmod +x cloudflared\n","\n","# -----------------------------\n","# Start Streamlit\n","# -----------------------------\n","print(\"â–¶ï¸ Menjalankan Streamlit...\")\n","\n","streamlit_proc = subprocess.Popen(\n","    [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"],\n","    stdout=subprocess.PIPE,\n","    stderr=subprocess.PIPE,\n",")\n","\n","time.sleep(3)\n","\n","# -----------------------------\n","# Start Cloudflare Tunnel\n","# -----------------------------\n","print(\"ðŸŒ Membuka Cloudflare Tunnel...\\n\")\n","\n","cloudflared = subprocess.Popen(\n","    [\"./cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8501\", \"--no-autoupdate\"],\n","    stdout=subprocess.PIPE,\n","    stderr=subprocess.PIPE,\n",")\n","\n","public_url = None\n","\n","print(\"ðŸ”Ž Mencari URL publik...\\n\")\n","\n","# Cari URL yang keluar di terminal cloudflare\n","while True:\n","    line = cloudflared.stdout.readline().decode(\"utf-8\")\n","    if \"trycloudflare.com\" in line:\n","        match = re.search(r\"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\", line)\n","        if match:\n","            public_url = match.group(0)\n","            break\n","\n","if public_url:\n","    print(\"ðŸš€ STREAMLIT AMS SIAP!\\n\")\n","    print(\"ðŸ”— URL Akses:\")\n","    print(public_url)\n","else:\n","    print(\"âŒ Gagal mengambil URL publik.\")\n"],"metadata":{"id":"CNtOgnvOqmFJ"},"execution_count":null,"outputs":[]}]}